
import os
import json
import time
import streamlit as st
import pandas as pd

from typing import Any

from rag_core import (
    ensure_index, hybrid_search, filter_df, parse_year_term_plan,
    extract_interests, recommend_courses, build_context, format_course_row, find_prerequisite_courses, find_prerequisite_direct
)
from config import MODEL

# LiteLLM
from litellm import completion

EXCEL_PATH = "cs_coursedata.xlsx"

st.set_page_config(page_title="AI Course Advisor", page_icon="üéì", layout="wide")

@st.cache_data(show_spinner=False)
def load_data(excel_path: str):
    df = pd.read_excel(excel_path)
    # Keep only the known columns (as in the file)
    cols = ['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤','‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤','‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï','‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏','‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤','‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô','‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô','‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤','‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤']
    df = df[[c for c in cols if c in df.columns]].copy()
    # Normalize types for robust filtering
    for c in ["‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤","‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤","‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏","‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤","‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤","‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤"]:
        if c in df.columns: df[c] = df[c].astype(str)
    for c in ["‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô","‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô","‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï"]:
        if c in df.columns: df[c] = df[c].astype(str)
    return df

@st.cache_resource(show_spinner=True)
def get_index_bundle(df, excel_path: str):
    # cache_dir in the app folder
    cache_dir = os.path.join(os.path.dirname(excel_path), ".faiss_cache")
    bundle = ensure_index(df, excel_path, cache_dir=cache_dir)
    # we don't cache the st_model to keep memory light; ensure_index returns cached on disk
    return bundle

def call_llm(system_prompt: str, user_prompt: str, model_name: str, max_tokens: int = 600) -> str:
    resp = completion(
        model=model_name,
        messages=[
            {"role":"system","content":system_prompt},
            {"role":"user","content":user_prompt}
        ],
        temperature=0.4,
        max_tokens=max_tokens
    )
    try:
        return resp["choices"][0]["message"]["content"]
    except Exception:
        return str(resp)

def system_prompt_th():
    return (
        "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏Ñ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (context) ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô "
        "‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó "
        "‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ tools ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ:\n"
        "1. search_courses_by_topic - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠/‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤\n"
        "2. find_prerequisite_courses - ‡∏´‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠\n"
        "‡πÉ‡∏ä‡πâ tools ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ "
        "‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å tools"
    )

def build_user_prompt(question: str, context: str) -> str:
    guide = (
        "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:\n\n"
        "### ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó\n"
        f"{context}\n\n"
        "### ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n"
        f"{question}\n\n"
        "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ñ‡∏≤‡∏°‡∏ñ‡∏∂‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï/‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö/‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:\n"
        "- ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï: ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï'\n"
        "- ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤ (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å): ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤'\n"
        "- ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤'\n"
        "- ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç/‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏π‡πâ: '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏'\n"
        "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ñ‡∏≤‡∏°‡∏ñ‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏' ‡∏ó‡∏µ‡πà‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏≤‡∏° \n"
    )
    return guide

def system_prompt_recommend_th():
    return (
        "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏Ñ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå "
        "‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ "
        "‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (Context) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡πÉ‡∏´‡∏°‡πà "
        "‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ‡∏°‡∏≤ (‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô) "
        "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡∏à‡∏∂‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö"
    )

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
    # excel_path = st.sidebar.text_input("‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå Excel", value="cs_coursedata.xlsx")
    # model_name = st.sidebar.text_input("LiteLLM Model", value="gpt-4o-mini")
    llm_token = st.slider("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Token ‡∏ó‡∏µ‡πà‡πÉ‡∏Ç‡πâ", min_value=800, max_value=2000, value=1500, step=50)
    alpha = st.slider("‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (alpha)", min_value=0.0, max_value=1.0, value=0.6, step=0.05)
    topk = st.slider("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á (k)", min_value=5, max_value=15, value=10, step=1)
    use_llm_rec = st.checkbox("‡πÉ‡∏ä‡πâ LLM ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (RAG)", value=True)

    st.caption("‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ENV ‡πÄ‡∏ä‡πà‡∏ô OPENAI_API_KEY ‡∏´‡∏£‡∏∑‡∏≠ LITELLM_API_KEY ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô‡πÅ‡∏≠‡∏õ")

# Main
st.title("üéì LLM Course Advisor üéì")
st.markdown(
    "‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel ‡πÅ‡∏•‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö **‡πÑ‡∏Æ‡∏ö‡∏£‡∏¥‡∏î** (semantic + keyword) ‡∏û‡∏£‡πâ‡∏≠‡∏° **‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ/‡πÄ‡∏ó‡∏≠‡∏°/‡πÅ‡∏ú‡∏ô** ‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ LLM"
)

# Load data + index
df = load_data(EXCEL_PATH)
bundle = get_index_bundle(df, EXCEL_PATH)

# Filter UI
with st.expander("‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÉ‡∏ä‡πâ‡∏Å‡πà‡∏≠‡∏ô RAG)", expanded=True):
    c1, c2, c3, c4 = st.columns(4)
    year = c1.selectbox("‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", ("‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "1", "2", "3", "4"))
    term = c2.selectbox("‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô", ("‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "1", "2"))
    plan = c3.selectbox("‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", ("‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡πÅ‡∏ú‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥", "‡πÅ‡∏ú‡∏ô‡∏™‡∏´‡∏Å‡∏¥‡∏à", "‡πÅ‡∏ú‡∏ô‡∏Å‡πâ‡∏≤‡∏ß‡∏´‡∏ô‡πâ‡∏≤"))
    course_type = c4.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤", ("‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö", "‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"))

def apply_filters(df, year, term, plan, course_type):
    year_v = None if year == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else year
    term_v = None if term == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else term
    plan_v = None if plan == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else plan
    tmp = filter_df(df, year_v, term_v, plan_v)
    if course_type != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" and "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤" in tmp.columns:
        if course_type == "‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö":
            tmp = tmp[tmp["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤"].astype(str).str.contains("‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö|‡πÅ‡∏Å‡∏ô", na=False)]
        elif course_type == "‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å":
            tmp = tmp[tmp["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤"].astype(str).str.contains("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å", na=False)]

    return tmp

df_filtered = apply_filters(df, year, term, plan, course_type)

st.markdown(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á:** {len(df_filtered)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
with st.expander("‡∏î‡∏π‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á"):
    showed_cols = ["‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤", "‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï", "‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô"]
    showed_cols = [c for c in showed_cols if c in df_filtered.columns]
    st.dataframe(df_filtered[showed_cols].reset_index(drop=True))

# Chat state
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role":"assistant","content":"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ! ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô '‡∏ß‡∏¥‡∏ä‡∏≤ 204xxx ‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï' ‡∏´‡∏£‡∏∑‡∏≠ '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ä‡∏≤‡∏õ‡∏µ 3 ‡πÄ‡∏ó‡∏≠‡∏° 1 ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI'"}
    ]

# Chat history UI
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])


# ‡πÄ‡∏û‡∏¥‡πà‡∏° tool definition ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å load_data
def get_tools_definition():
    return [
        {
            "type": "function",
            "function": {
                "name": "search_courses_by_topic",
                "description": "‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÄ‡∏ä‡πà‡∏ô AI, hardware, database, web development",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "topic": {
                            "type": "string",
                            "description": "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô 'AI', 'machine learning', 'hardware', 'network'"
                        },
                        "limit": {
                            "type": "integer",
                            "description": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•",
                            "default": 5
                        }
                    },
                    "required": ["topic"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "find_prerequisite_courses",
                "description": "‡∏´‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠ (prerequisite) ‡πÇ‡∏î‡∏¢‡πÄ‡∏ä‡πá‡∏Ñ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "course_code": {
                            "type": "string",
                            "description": "‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô '204111', '204101'"
                        }
                    },
                    "required": ["course_code"]
                }
            }
        }
    ]

# ‡πÄ‡∏û‡∏¥‡πà‡∏° function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡∏û‡∏£‡πâ‡∏≠‡∏° tools
def call_llm_with_tools(system_prompt: str, user_prompt: str, model_name: str, tools: list, max_tokens: int = 800):
    """Call LLM with tool support"""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    resp = completion(
        model=model_name,
        messages=messages,
        tools=tools,
        tool_choice="auto",
        temperature=0.4,
        max_tokens=max_tokens
    )
    return resp

# ‡πÄ‡∏û‡∏¥‡πà‡∏° function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ tool calls
def execute_tool_call(tool_name: str, arguments: dict) -> str:
    """Execute the requested tool and return results"""
    
    if tool_name == "search_courses_by_topic":
        topic = arguments.get("topic", "")
        limit = arguments.get("limit", 5)
        
        from rag_core import search_courses_by_topic
        results = search_courses_by_topic(df_filtered, topic, bundle, limit=limit)
        
        if results.empty:
            return f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö '{topic}'"
        
        lines = [f"‡∏û‡∏ö {len(results)} ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö '{topic}':\n"]
        for idx, row in results.iterrows():
            line = f"- {row['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤']} {row['‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤']} ({row['‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï']} ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï)"
            if pd.notna(row.get('‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤')):
                line += f"\n  ‚Ä¢ {row['‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤'][:150]}..."
            lines.append(line)
        
        return "\n".join(lines)
    
    elif tool_name == "find_prerequisite_courses":
        course_code = arguments.get("course_code", "")
        
        from rag_core import find_prerequisite_courses
        results = find_prerequisite_courses(df_filtered, course_code)
        
        if results.empty:
            return f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ {course_code} ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠ (prerequisite)"
        
        lines = [f"‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô {course_code} ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡∏°‡∏µ {len(results)} ‡∏ß‡∏¥‡∏ä‡∏≤:\n"]
        for idx, row in results.iterrows():
            line = f"- {row['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤']} {row['‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤']}"
            if pd.notna(row.get('‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏')):
                line += f"\n  ‚Ä¢ ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: {row['‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏']}"
            if pd.notna(row.get('‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤')):
                line += f"\n  ‚Ä¢ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö: {row['‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤'][:100]}..."
            lines.append(line)
        
        return "\n".join(lines)
    
    return f"‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å tool: {tool_name}"


def answer_general_with_tools(question: str) -> str:
    """Answer with tool calling support"""
    tools = get_tools_definition()
    sys = system_prompt_th()
    
    # First call to LLM
    resp = call_llm_with_tools(sys, question, MODEL, tools, max_tokens=llm_token)
    
    # Check if LLM wants to use tools
    message = resp["choices"][0]["message"]
    
    if message.get("tool_calls"):
        # Execute tool calls
        tool_results = []
        for tool_call in message["tool_calls"]:
            func_name = tool_call["function"]["name"]
            arguments = json.loads(tool_call["function"]["arguments"])
            result = execute_tool_call(func_name, arguments)
            tool_results.append(result)
        
        # Second call with tool results
        messages = [
            {"role": "system", "content": sys},
            {"role": "user", "content": question},
            message,
            {"role": "tool", "tool_call_id": message["tool_calls"][0]["id"], 
             "content": "\n\n".join(tool_results)}
        ]
        
        final_resp = completion(
            model=MODEL,
            messages=messages,
            temperature=0.4,
            max_tokens=llm_token
        )
        return final_resp["choices"][0]["message"]["content"]
    
    # No tool calls, return direct response
    return answer_general(question)

def answer_general(question: str) -> str:
    # Hybrid search on filtered df
    hits = hybrid_search(question, df_filtered, bundle, k=topk, alpha=alpha)
    if not hits:
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏ß‡πâ"

    context = build_context(df_filtered, hits)
    sys = system_prompt_th()
    user = build_user_prompt(question, context)
    return call_llm(sys, user, model_name=MODEL, max_tokens=llm_token)

def answer_recommend(question: str, num_of_course:int = 5) -> str:
    info = parse_year_term_plan(question)
    tmp = df
    # Enforce filter as spec: filter BEFORE RAG/recommend
    tmp = apply_filters(tmp,
                        info["year"] if info["year"] else year,
                        info["term"] if info["term"] else term,
                        info["plan"] if info["plan"] else plan,
                        course_type)
    if tmp.empty:
        return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏£‡∏≠‡∏á"

    interests = extract_interests(question)
    recs = recommend_courses(tmp, interests, limit=8)

    lines = []
    if interests:
        lines.append(f"**‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ:** {', '.join(interests)}")
    lines.append("**‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**")
    course_counter = 0
    for _, row in recs.iterrows():
        if course_counter < num_of_course:
            bullet = f"- {row['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤']} {row['‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤']}\n‚Ä¢ {row['‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï']} ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï | {row['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤']} | ‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô : ‡πÄ‡∏ó‡∏≠‡∏° {row['‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô']} | ‡πÅ‡∏ú‡∏ô: {row['‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤']}"
            if str(row.get("‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤","")).strip():
                bullet += f"\n  ‚Ä¢ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤: {row['‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤']}"
            if str(row.get("‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏","")).strip():
                bullet += f"\n  ‚Ä¢ ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: {row['‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏']}"
            lines.append(bullet)
            course_counter += 1
        else:
            break
    return "\n".join(lines)

def answer_recommend_llm(question: str) -> str:
    # 1) parse ‡∏õ‡∏µ/‡πÄ‡∏ó‡∏≠‡∏°/‡πÅ‡∏ú‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    info = parse_year_term_plan(question)

    # 2) ‡∏Å‡∏£‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô (‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å UI ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°)
    tmp = apply_filters(
        df,
        info["year"] if info["year"] else year,
        info["term"] if info["term"] else term,
        info["plan"] if info["plan"] else plan,
        course_type
    )
    if tmp.empty:
        return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏£‡∏≠‡∏á"

    # 3) ‡∏î‡∏∂‡∏á‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡πâ‡∏≤‡∏ä‡∏¥‡∏á
    interests = extract_interests(question)
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤‡∏Å‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LLM‡∏°‡∏µ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
    recs = recommend_courses(tmp, interests, limit=12)

    # (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) ‡∏ú‡∏™‡∏°‡∏ú‡∏• hybrid_search ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏µ‡∏Å‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
    # hits = hybrid_search(" ".join(interests) or question, tmp, bundle, k=5, alpha=alpha)
    # ctx_hits = build_context(tmp, hits)

    # 4) ‡∏™‡∏£‡πâ‡∏≤‡∏á Context ‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ recs ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô)
    lines = []
    for _, row in recs.iterrows():
        lines.append(format_course_row(row))
    context = "\n\n---\n\n".join(lines)
    # context = context + ("\n\n" + ctx_hits if ctx_hits else "")  # ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏°

    # 5) Prompt ‡πÄ‡∏Ç‡πâ‡∏≤ LLM (‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤‡πÉ‡∏ô Context)
    sys = system_prompt_recommend_th()
    guide = (
        "‡∏à‡∏á‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÇ‡∏î‡∏¢‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô Context "
        "(‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) "
        "‡∏´‡πâ‡∏≤‡∏°‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô Context "
        "‡∏´‡∏≤‡∏Å Context ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏' ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ.\n"
        f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ: {', '.join(interests) if interests else '‚Äî'}"
    )
    user = (
        f"{guide}\n\n### Context\n{context}\n\n"
        f"### ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\n{question}\n\n"
        "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: ‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ 1-2 ‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ bullet ‡∏™‡∏£‡∏∏‡∏õ (1) ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö (2) ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"
    )

    return call_llm(sys, user, model_name=MODEL, max_tokens=llm_token)

def is_recommend_intent(text: str) -> bool:
    keys = ["‡∏à‡∏±‡∏î","‡∏•‡∏á‡∏ß‡∏¥‡∏ä‡∏≤","‡∏Ñ‡∏ß‡∏£‡∏•‡∏á","‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô","‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"]
    return any(k in text for k in keys)


# Chat input
q = st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...")
if q:
    st.session_state.messages.append({"role":"user","content":q})

    with st.chat_message("assistant"):
        if is_recommend_intent(q):
            ans = answer_recommend_llm(q) if use_llm_rec else answer_recommend(q)
        else:
            ans = answer_general_with_tools(q)

        st.markdown(ans)
        st.session_state.messages.append({"role":"assistant","content":ans})

# Tools
cA, cB, cC = st.columns([1,1,1])
with cA:
    if st.button("‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó"):
        st.session_state.messages = []
        st.rerun()
with cB:
    if st.button("‡∏î‡∏π‡∏ß‡∏¥‡∏ä‡∏≤ '‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö' ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á)"):
        if "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤" in df_filtered.columns:
            sub = df_filtered[df_filtered["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤"].astype(str).str.contains("‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö", na=False)]
            st.dataframe(sub.reset_index(drop=True))
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤'")
with cC:
    st.download_button(
        "‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô CSV",
        data=df_filtered.to_csv(index=False).encode("utf-8-sig"),
        file_name="filtered_courses.csv",
        mime="text/csv"
    )
