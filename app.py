import os
import json
import streamlit as st
import pandas as pd
import base64

from pathlib import Path
from utils.llm_client import LLMClient, get_available_models
from typing import Any

from rag_core import (
    ensure_index, hybrid_search, filter_df, parse_year_term_plan,
    extract_interests, recommend_courses, build_context, format_course_row,
    search_courses_by_topic, find_prerequisite_courses
)

from config import MODEL
from litellm import completion

EXCEL_PATH = "cs_coursedata.xlsx"


def get_base64_image(image_file):
    if not os.path.exists(image_file):
        return ""

    try:
        with open(image_file, "rb") as f:
            return base64.b64encode(f.read()).decode()
    except Exception:
        return ""


def init_session_state():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "llm_client" not in st.session_state:
        st.session_state.llm_client = None
    if "rag_system" not in st.session_state:
        st.session_state.rag_system = None
    if "rag_initialized" not in st.session_state:
        st.session_state.rag_initialized = False
    if "is_model_ready" not in st.session_state:
        st.session_state.is_model_ready = False
    if "is_rag_ready" not in st.session_state:
        st.session_state.is_rag_ready = False


def load_css(styles: str):
    with open(styles, "r", encoding="utf-8") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)


@st.cache_data(show_spinner=False)
def load_data(excel_path: str):
    df = pd.read_excel(excel_path)
    cols = ['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤', '‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï', '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏', '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤', '‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô', '‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô',
            '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤', '‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤']
    df = df[[c for c in cols if c in df.columns]].copy()
    for c in ["‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤", "‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤", "‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏", "‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤", "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤", "‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤"]:
        if c in df.columns: df[c] = df[c].astype(str)
    for c in ["‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô", "‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï"]:
        if c in df.columns: df[c] = df[c].astype(str)
    return df


@st.cache_resource(show_spinner=True)
def get_index_bundle(df, excel_path: str):
    # cache_dir in the app folder
    cache_dir = os.path.join(os.path.dirname(excel_path), ".faiss_cache")
    bundle = ensure_index(df, excel_path, cache_dir=cache_dir)
    return bundle


def apply_filters(df, year, term, plan, course_type):
    year_v = None if year == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else year
    term_v = None if term == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else term
    plan_v = None if plan == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else plan
    tmp = filter_df(df, year_v, term_v, plan_v)
    if course_type != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" and "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤" in tmp.columns:
        if course_type == "‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö":
            tmp = tmp[tmp["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤"].astype(str).str.contains("‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö|‡πÅ‡∏Å‡∏ô", na=False)]
        elif course_type == "‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å":
            tmp = tmp[tmp["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤"].astype(str).str.contains("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å", na=False)]

    return tmp


def call_llm(system_prompt: str, user_prompt: str, model_name: str, max_tokens: int = 600):
    resp = completion(
        model=model_name,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=temperature,
        max_tokens=max_tokens
    )
    try:
        return resp["choices"][0]["message"]["content"]
    except Exception:
        return str(resp)


def system_prompt_th():
    return (
        "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏Ñ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (context) ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô "
        "‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏Ç‡∏≤‡∏î‡∏ï‡∏Å‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó"
        "‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ tools ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ:\n"
        "1. search_courses_by_topic - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠/‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤\n"
        "2. find_prerequisite_courses - ‡∏´‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠\n"
        "‡πÉ‡∏ä‡πâ tools ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ "
        "‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å tools"
    )


def build_user_prompt(question: str, context: str):
    guide = (
        "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:\n\n"
        "### ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó\n"
        f"{context}\n\n"
        "### ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n"
        f"{question}\n\n"
        "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ñ‡∏≤‡∏°‡∏ñ‡∏∂‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï/‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö/‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:\n"
        "- ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï: ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï'\n"
        "- ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤ (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å): ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤'\n"
        "- ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤'\n"
        "- ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç/‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏π‡πâ: '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏'\n"
        "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ñ‡∏≤‡∏°‡∏ñ‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏' ‡∏ó‡∏µ‡πà‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏≤‡∏° \n"
    )
    return guide


def system_prompt_recommend_th():
    return (
        "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏Ñ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå "
        "‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ "
        "‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (Context) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡πÉ‡∏´‡∏°‡πà "
        "‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ‡∏°‡∏≤ (‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô) "
        "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡∏à‡∏∂‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô"
    )


def get_tools_definition():
    return [
        {
            "type": "function",
            "function": {
                "name": "search_courses_by_topic",
                "description": "‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÄ‡∏ä‡πà‡∏ô AI, hardware, database, web development",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "topic": {
                            "type": "string",
                            "description": "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô 'AI', 'machine learning', 'hardware', 'network'"
                        },
                        "limit": {
                            "type": "integer",
                            "description": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•",
                            "default": 5
                        }
                    },
                    "required": ["topic"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "find_prerequisite_courses",
                "description": "‡∏´‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠ (prerequisite) ‡πÇ‡∏î‡∏¢‡πÄ‡∏ä‡πá‡∏Ñ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "course_code": {
                            "type": "string",
                            "description": "‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô '204111', '204101'"
                        }
                    },
                    "required": ["course_code"]
                }
            }
        }
    ]


def call_llm_with_tools(system_prompt: str, user_prompt: str, model_name: str, tools: list, max_tokens: int = 800):
    """Call LLM with tool support"""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    resp = completion(
        model=model_name,
        messages=messages,
        tools=tools,
        tool_choice="auto",
        temperature=temperature,
        max_tokens=max_tokens
    )
    return resp


def execute_tool_call(tool_name: str, arguments: dict):
    """Execute the requested tool and return results"""

    if tool_name == "search_courses_by_topic":
        topic = arguments.get("topic", "")
        limit = arguments.get("limit", 5)

        results = search_courses_by_topic(df_filtered, topic, bundle, limit=limit)

        if results.empty:
            return f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö '{topic}'"

        lines = [f"‡∏û‡∏ö {len(results)} ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö '{topic}':\n"]
        for idx, row in results.iterrows():
            line = f"- {row['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤']} {row['‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤']} ({row['‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï']} ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï)"
            if pd.notna(row.get('‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤')):
                line += f"\n  ‚Ä¢ {row['‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤'][:150]}..."
            lines.append(line)

        return "\n".join(lines)

    elif tool_name == "find_prerequisite_courses":
        course_code = arguments.get("course_code", "")

        results = find_prerequisite_courses(df_filtered, course_code)

        if results.empty:
            return f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ {course_code} ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠ (prerequisite)"

        lines = [f"‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô {course_code} ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡∏°‡∏µ {len(results)} ‡∏ß‡∏¥‡∏ä‡∏≤:\n"]
        for idx, row in results.iterrows():
            line = f"- {row['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤']} {row['‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤']}"
            if pd.notna(row.get('‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏')):
                line += f"\n  ‚Ä¢ ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: {row['‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏']}"
            if pd.notna(row.get('‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤')):
                line += f"\n  ‚Ä¢ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö: {row['‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤'][:100]}..."
            lines.append(line)

        return "\n".join(lines)

    return f"‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å tool: {tool_name}"


def answer_general_with_tools(question: str, tool_name: str = "") -> str:
    """Answer with tool calling support"""
    tools = get_tools_definition()
    sys = system_prompt_th()

    resp = call_llm_with_tools(sys, question, MODEL, tools, max_tokens=max_tokens)

    message = resp["choices"][0]["message"]

    if message.get("tool_calls"):
        # Execute tool calls
        # print("tool called")
        tool_results = []
        for tool_call in message["tool_calls"]:
            func_name = tool_call["function"]["name"]
            arguments = json.loads(tool_call["function"]["arguments"])
            result = execute_tool_call(func_name, arguments)
            tool_results.append(result)

        messages = [
            {"role": "system", "content": sys},
            {"role": "user", "content": question},
            message,
            {"role": "tool", "tool_call_id": message["tool_calls"][0]["id"],
             "content": "\n\n".join(tool_results)}
        ]

        final_resp = completion(
            model=MODEL,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        return final_resp["choices"][0]["message"]["content"]

    return answer_general(question)


def answer_general(question: str):
    # Hybrid search on filtered df
    hits = hybrid_search(question, df_filtered, bundle, k=topk, alpha=alpha)
    if not hits:
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏ß‡πâ"

    context = build_context(df_filtered, hits)
    sys = system_prompt_th()
    user = build_user_prompt(question, context)
    return call_llm(sys, user, model_name=selected_model, max_tokens=max_tokens)


def answer_recommend(question: str, num_of_course: int = 5):
    info = parse_year_term_plan(question)
    tmp = df
    # Enforce filter as spec filter BEFORE RAG recommend
    tmp = apply_filters(tmp,
                        info["year"] if info["year"] else year,
                        info["term"] if info["term"] else term,
                        info["plan"] if info["plan"] else plan,
                        course_type)
    if tmp.empty:
        return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á"

    interests = extract_interests(question)
    recs = recommend_courses(tmp, interests, limit=8)

    lines = []
    if interests:
        lines.append(f"**‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ:** {', '.join(interests)}")
    lines.append("**‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**")
    course_counter = 0
    for _, row in recs.iterrows():
        if course_counter < num_of_course:
            bullet = f"- {row['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤']} {row['‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤']}\n‚Ä¢ {row['‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï']} ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï | {row['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤']} | ‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô : ‡πÄ‡∏ó‡∏≠‡∏° {row['‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô']} | ‡πÅ‡∏ú‡∏ô: {row['‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤']}"
            if str(row.get("‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤", "")).strip():
                bullet += f"\n  ‚Ä¢ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤: {row['‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤']}"
            if str(row.get("‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏", "")).strip():
                bullet += f"\n  ‚Ä¢ ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: {row['‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏']}"
            lines.append(bullet)
            course_counter += 1
        else:
            break
    return "\n".join(lines)


def answer_recommend_llm(question: str):
    info = parse_year_term_plan(question)

    tmp = apply_filters(
        df,
        info["year"] if info["year"] else year,
        info["term"] if info["term"] else term,
        info["plan"] if info["plan"] else plan,
        course_type
    )
    if tmp.empty:
        return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏£‡∏≠‡∏á"
    interests = extract_interests(question)

    recs = recommend_courses(tmp, interests, limit=12)

    lines = []
    for _, row in recs.iterrows():
        lines.append(format_course_row(row))
    context = "\n\n---\n\n".join(lines)

    sys = system_prompt_recommend_th()
    guide = (
        "‡∏à‡∏á‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÇ‡∏î‡∏¢‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô Context "
        "(‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) "
        "‡∏´‡πâ‡∏≤‡∏°‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô Context "
        "‡∏´‡∏≤‡∏Å Context ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏' ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ.\n"
        f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ: {', '.join(interests) if interests else '‚Äî'}"
    )
    user = (
        f"{guide}\n\n### Context\n{context}\n\n"
        f"### ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\n{question}\n\n"
        "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: ‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ 1-2 ‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ bullet ‡∏™‡∏£‡∏∏‡∏õ (1) ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö (2) ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"
    )

    return call_llm(sys, user, model_name=selected_model, max_tokens=max_tokens)


def is_recommend_intent(text: str):
    keys = ["‡∏à‡∏±‡∏î", "‡∏ï‡∏≠‡∏ô", "‡∏ß‡∏¥‡∏ä‡∏≤", "‡∏•‡∏á‡∏ß‡∏¥‡∏ä‡∏≤", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤", "‡∏ß‡∏¥‡∏ä‡∏≤‡∏≠‡∏∞‡πÑ‡∏£", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏≠‡∏∞‡πÑ‡∏£", "‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏∞‡πÑ‡∏£", "‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ä‡πà‡∏ß‡∏¢",
            "‡∏Ñ‡∏ß‡∏£‡∏•‡∏á", "‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô", "‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡∏ï‡πâ‡∏≠‡∏á‡∏ú‡πà‡∏≤‡∏ô", "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö", "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å", "‡πÅ‡∏ú‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥", "‡πÅ‡∏ú‡∏ô‡∏™‡∏´‡∏Å‡∏¥‡∏à",
            "‡πÅ‡∏ú‡∏ô‡∏Å‡πâ‡∏≤‡∏ß‡∏´‡∏ô‡πâ‡∏≤", "‡∏õ‡∏Å‡∏ï‡∏¥", "‡∏™‡∏´‡∏Å‡∏¥‡∏à", "‡∏Å‡πâ‡∏≤‡∏ß‡∏´‡∏ô‡πâ‡∏≤"]
    return any(k in text for k in keys)


def is_topic_tool_intent(text: str):
    keys = ["‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠", "‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß", "‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö", "‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢", "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á", "‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"]
    t = text.lower()
    return any(k in t for k in keys)


def is_prereq_tool_intent(text: str):
    keys = ["‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠", "‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å", "‡∏ï‡πà‡∏≠", "‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ", "‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤", "‡πÉ‡∏ä‡πâ"]
    t = text.lower()
    return any(k in t for k in keys)


def main():
    global max_tokens, alpha, topk, use_llm_rec, selected_model, temperature
    global df, bundle, df_filtered, year, term, plan, course_type

    # title
    st.set_page_config(
        page_title="Courses Advisor",
        page_icon="üìö",
        layout="wide"
    )

    init_session_state()
    load_css("styles.css")

    header_col1, header_col2, header_col3 = st.columns([1, 10, 1])

    with header_col2:
        st.markdown("""
        <div style="text-align: center;">
            <h1 class="gradient-title" style="font-size: 3.5em; line-height: 0.5; font-weight: 700;">
                Courses Advisor
            </h1>
            <p class="subtitle" style="font-size: 1.5em; font-weight: 600;">
                This is a RAG-powered Courses Adviser for CS CMU projects.
            </p>
        </div>
        """, unsafe_allow_html=True)

    with st.sidebar:
        col1, col2, col3 = st.columns([1, 3, 1])
        with col2:
            current_dir = os.path.dirname(__file__)
            logo_path = os.path.join(current_dir, "png", "cslogowhite.png")

            if os.path.exists(logo_path):
                st.image(logo_path, width=100)
            else:
                st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏•‡πÇ‡∏Å‡πâ: {logo_path}")
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")

        # Filter UI And Clear Chat
        with st.expander("‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", expanded=False):
            year = st.selectbox("‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", ("‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "1", "2", "3", "4"))
            term = st.selectbox("‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô", ("‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "1", "2"))
            plan = st.selectbox("‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", ("‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡πÅ‡∏ú‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥", "‡πÅ‡∏ú‡∏ô‡∏™‡∏´‡∏Å‡∏¥‡∏à", "‡πÅ‡∏ú‡∏ô‡∏Å‡πâ‡∏≤‡∏ß‡∏´‡∏ô‡πâ‡∏≤"))
            course_type = st.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤", ("‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö", "‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"))

        # ‡∏õ‡∏£‡∏±‡∏ö RAG
        with st.expander("‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤", expanded=False):
            temperature = st.slider("Temperature", min_value=0.1, max_value=1.0, value=0.4, step=0.1,
                                    help="‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°")
            max_tokens = st.slider("Max Tokens", min_value=500, max_value=2500, value=1500, step=100,
                                   help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ")
            alpha = st.slider("‡∏Ñ‡πà‡∏≤ Alpha", min_value=0.0, max_value=1.0, value=0.6, step=0.05,
                              help="Alpha ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö 1 ‡∏à‡∏∞‡πÉ‡∏ä‡πâ Vector ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤ ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö 0 ‡∏à‡∏∞‡πÉ‡∏ä‡πâ Keyword")
            topk = st.slider("‡∏Ñ‡πà‡∏≤ k", min_value=5, max_value=15, value=10, step=1, help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á")

        st.divider()
        available_models = get_available_models()
        selected_model = st.selectbox(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•",
            available_models,
            index=1,
            help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ"
        )

        with st.spinner("Initializing model..."):
            st.session_state.llm_client = LLMClient(
                model=selected_model,
                temperature=temperature,
                max_tokens=max_tokens)

        # ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á
        st.info(f"‚ö° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• {selected_model}")
        # st.markdown(selected_model)
        use_llm_rec = st.checkbox("‡πÉ‡∏ä‡πâ LLM ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (RAG)", value=True)

        st.divider()

        # Clear Chat
        if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏ó"):
            st.session_state.messages = []
            st.rerun()

    # Load data + index
    df = load_data(EXCEL_PATH)
    bundle = get_index_bundle(df, EXCEL_PATH)

    df_filtered = apply_filters(df, year, term, plan, course_type)

    # Chat state
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant",
             "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ! ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô \"‡∏õ‡∏µ 2 ‡πÄ‡∏ó‡∏≠‡∏° 2 ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á\" ‡∏´‡∏£‡∏∑‡∏≠ \"‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ä‡∏≤‡∏õ‡∏µ 3 ‡πÄ‡∏ó‡∏≠‡∏° 1 ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI\""}
        ]

    # Chat history UI
    for msg in st.session_state.messages:
        avatar = msg.get("avatar", "png/avatar_bot.png")
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    # Chat input
    q = st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...")
    if q:
        st.session_state.messages.append({"role": "user", "content": q, "avatar": "png/avatar_user.png"})
        with st.chat_message("user", avatar="png/avatar_user.png"):
            st.markdown(q)
        with st.chat_message("assistant", avatar="png/avatar_bot.png"):
            with st.spinner("Processing..."):
                if is_topic_tool_intent(q):
                    ans = answer_general_with_tools(q, "search_courses_by_topic")

                elif is_prereq_tool_intent(q):
                    ans = answer_general_with_tools(q, "find_prerequisite_courses")

                elif is_recommend_intent(q):
                    ans = answer_recommend_llm(q) if use_llm_rec else answer_recommend(q)

                else:
                    ans = answer_general_with_tools(q)
                st.markdown(ans)
                st.session_state.messages.append({"role": "assistant", "content": ans, "avatar": "png/avatar_bot.png"})

    # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Å‡∏£‡∏≠‡∏á
    st.markdown(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á:** {len(df_filtered)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    with st.expander("‡∏î‡∏π‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á"):
        showed_cols = ["‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤", "‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï", "‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô"]
        showed_cols = [c for c in showed_cols if c in df_filtered.columns]
        st.dataframe(df_filtered[showed_cols].reset_index(drop=True))

    # Example
    cA, cB, cC = st.columns(3)
    with cA:
        button_A = st.button("‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI")

    with cB:
        button_B = st.button("‡∏ß‡∏¥‡∏ä‡∏≤‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡∏Ç‡∏≠‡∏á 204252")

    with cC:
        st.download_button(
            "‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô CSV",
            data=df_filtered.to_csv(index=False).encode("utf-8-sig"),
            file_name="filtered_courses.csv",
            mime="text/csv"
        )
    if button_A:
        q = "‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI"
        st.session_state.messages.append({"role": "user", "content": q, "avatar": "png/avatar_user.png"})
        with st.chat_message("user", avatar="png/avatar_user.png"):
            st.markdown(q)
        with st.chat_message("assistant", avatar="png/avatar_bot.png"):
            with st.spinner("Processing..."):
                if is_topic_tool_intent(q):
                    ans = answer_general_with_tools(q, "search_courses_by_topic")

                elif is_prereq_tool_intent(q):
                    ans = answer_general_with_tools(q, "find_prerequisite_courses")

                elif is_recommend_intent(q):
                    ans = answer_recommend_llm(q) if use_llm_rec else answer_recommend(q)

                else:
                    ans = answer_general_with_tools(q)
                st.markdown(ans)
                st.session_state.messages.append({"role": "assistant", "content": ans, "avatar": "png/avatar_bot.png"})

    if button_B:
        q = "‡∏ß‡∏¥‡∏ä‡∏≤‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡πà‡∏≠‡∏Ç‡∏≠‡∏á 204252"
        st.session_state.messages.append({"role": "user", "content": q, "avatar": "png/avatar_user.png"})
        with st.chat_message("user", avatar="png/avatar_user.png"):
            st.markdown(q)
        with st.chat_message("assistant", avatar="png/avatar_bot.png"):
            with st.spinner("Processing..."):
                if is_topic_tool_intent(q):
                    ans = answer_general_with_tools(q, "search_courses_by_topic")

                elif is_prereq_tool_intent(q):
                    ans = answer_general_with_tools(q, "find_prerequisite_courses")

                elif is_recommend_intent(q):
                    ans = answer_recommend_llm(q) if use_llm_rec else answer_recommend(q)

                else:
                    ans = answer_general_with_tools(q)
                st.markdown(ans)
                st.session_state.messages.append({"role": "assistant", "content": ans, "avatar": "png/avatar_bot.png"})


if __name__ == "__main__":
    main()
