
import os
import json
import time
import streamlit as st
import pandas as pd

from utils.llm_client import LLMClient, get_available_models

from rag_core import (
    ensure_index, hybrid_search, filter_df, parse_year_term_plan,
    extract_interests, recommend_courses, build_context, format_course_row
)
from config import MODEL

# LiteLLM
from litellm import completion

EXCEL_PATH = "/mnt/c/Users/petez/OneDrive/Documents/dawg_sheet/cs_coursedata.xlsx"


st.set_page_config(page_title="‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô (RAG+FAISS)", page_icon="üéì", layout="wide")

@st.cache_data(show_spinner=False)
def load_data(excel_path: str):
    df = pd.read_excel(excel_path)
    # Keep only the known columns (as in the file)
    cols = ['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤','‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤','‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï','‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏','‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤','‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô','‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô','‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤','‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤']
    df = df[[c for c in cols if c in df.columns]].copy()
    # Normalize types for robust filtering
    for c in ["‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤","‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤","‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏","‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤","‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤","‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤"]:
        if c in df.columns: df[c] = df[c].astype(str)
    for c in ["‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô","‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô","‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï"]:
        if c in df.columns: df[c] = df[c].astype(str)
    return df

@st.cache_resource(show_spinner=True)
def get_index_bundle(df, excel_path: str):
    # cache_dir in the app folder
    cache_dir = os.path.join(os.path.dirname(excel_path), ".faiss_cache")
    bundle, st_model = ensure_index(df, excel_path, cache_dir=cache_dir)
    # we don't cache the st_model to keep memory light; ensure_index returns cached on disk
    return bundle

def call_llm(system_prompt: str, user_prompt: str, model_name: str, max_tokens: int = 600) -> str:
    resp = completion(
        model=model_name,
        messages=[
            {"role":"system","content":system_prompt},
            {"role":"user","content":user_prompt}
        ],
        temperature=0.2,
        max_tokens=max_tokens
    )
    try:
        return resp["choices"][0]["message"]["content"]
    except Exception:
        return str(resp)

def system_prompt_th():
    return (
        "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏Ñ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (context) ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô "
        "‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó"
    )

def build_user_prompt(question: str, context: str) -> str:
    guide = (
        "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:\n\n"
        "### ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó\n"
        f"{context}\n\n"
        "### ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n"
        f"{question}\n\n"
        "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ñ‡∏≤‡∏°‡∏ñ‡∏∂‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï/‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö/‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:\n"
        "- ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï: ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï'\n"
        "- ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤ (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å): ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤'\n"
        "- ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤'\n"
        "- ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç/‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏π‡πâ: '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏'\n"
    )
    return guide
# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Settings")
    # Model selection
    available_models = get_available_models()
    selected_model = st.selectbox(
            "Select Model",
            available_models,
            index=0,
            help="Choose the language model to use"
        )

        # Temperature slider
    temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=2.0,
            value=0.6,
            step=0.1,
            help="Controls randomness in responses"
        )

        # Max tokens
    max_tokens = st.slider(
            "Max Tokens",
            min_value=50,
            max_value=4000,
            value=1000,
            step=50,
            help="Maximum length of response"
        )

    with st.spinner("Initializing model..."):
            st.session_state.llm_client = LLMClient(
                model=selected_model,
                temperature=temperature,
                max_tokens=max_tokens
        )
    st.markdown(selected_model)

    # Main
st.title("üéì LLM Course Advisor ‚Äî RAG + FAISS + LiteLLM")
st.markdown(
        "‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel ‡πÅ‡∏•‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö **‡πÑ‡∏Æ‡∏ö‡∏£‡∏¥‡∏î** (semantic + keyword) ‡∏û‡∏£‡πâ‡∏≠‡∏° **‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ/‡πÄ‡∏ó‡∏≠‡∏°/‡πÅ‡∏ú‡∏ô** ‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ LLM"
)
    

    
# Load data + index
df = load_data(EXCEL_PATH)
bundle = get_index_bundle(df, EXCEL_PATH)

# Filter UI Sidebar
st.sidebar.subheader("‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÉ‡∏ä‡πâ‡∏Å‡πà‡∏≠‡∏ô RAG)")
year = st.sidebar.selectbox("‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted({str(x) for x in df["‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"].dropna().unique()}))
term = st.sidebar.selectbox("‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô", ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted({str(x) for x in df["‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô"].dropna().unique()}))   


def apply_filters(df, year, term):
    year_v = None if year == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else year
    term_v = None if term == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" else term
    tmp = filter_df(df, year_v, term_v)
    # if course_type != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" and "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤" in tmp.columns:
    #     tmp = tmp[tmp["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤"].astype(str).str.contains(course_type, na=False)]
    return tmp

df_filtered = apply_filters(df, year, term)

# Chat state
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role":"assistant","content":"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ! ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô '‡∏ß‡∏¥‡∏ä‡∏≤ 204xxx ‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï' ‡∏´‡∏£‡∏∑‡∏≠ '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ä‡∏≤‡∏õ‡∏µ 3 ‡πÄ‡∏ó‡∏≠‡∏° 1 ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI'"}
    ]

# Chat history UI
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

def answer_general(question: str) -> str:
    # Hybrid search on filtered df
    hits = hybrid_search(question, df_filtered, bundle, k=topk, alpha=alpha)
    if not hits:
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏ß‡πâ"

    context = build_context(df_filtered, hits)
    sys = system_prompt_th()
    user = build_user_prompt(question, context)
    return call_llm(sys, user, model_name=MODEL)

def answer_recommend(question: str) -> str:
    info = parse_year_term_plan(question)
    tmp = df
    # Enforce filter as spec: filter BEFORE RAG/recommend
    tmp = apply_filters(tmp,
                        info["year"] if info["year"] else year,
                        info["term"] if info["term"] else term)
    if tmp.empty:
        return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏£‡∏≠‡∏á"

    interests = extract_interests(question)
    recs = recommend_courses(tmp, interests, limit=8)

    lines = []
    if interests:
        lines.append(f"**‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ:** {', '.join(interests)}")
    lines.append("**‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏Å‡πà‡∏≠‡∏ô):**")
    for _, row in recs.iterrows():
        bullet = f"- {row['‡∏£‡∏´‡∏±‡∏™‡∏ß‡∏¥‡∏ä‡∏≤']} {row['‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤']} ‚Äî {row['‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï']} ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï | {row['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤']} | ‡∏õ‡∏µ {row['‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô']} ‡πÄ‡∏ó‡∏≠‡∏° {row['‡πÄ‡∏ó‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≠‡∏ô']} | ‡πÅ‡∏ú‡∏ô: {row['‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤']}"
        if str(row.get("‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤","")).strip():
            bullet += f"\n  ‚Ä¢ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤: {row['‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤']}"
        if str(row.get("‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏","")).strip():
            bullet += f"\n  ‚Ä¢ ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: {row['‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏']}"
        lines.append(bullet)
    lines.append("\n*‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏ä‡πà‡∏ô '‡πÄ‡∏≠‡∏≤ 5 ‡∏ß‡∏¥‡∏ä‡∏≤' ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à*")
    return "\n".join(lines)

def is_recommend_intent(text: str) -> bool:
    keys = ["‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥","‡∏à‡∏±‡∏î","‡∏•‡∏á‡∏ß‡∏¥‡∏ä‡∏≤","‡∏Ñ‡∏ß‡∏£‡∏•‡∏á","‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô","‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"]
    return any(k in text for k in keys)

# Chat input
q = st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...")
if q:
    st.session_state.messages.append({"role":"user","content":q})
    with st.chat_message("assistant"):
        if is_recommend_intent(q):
            ans = answer_recommend(q)
        else:
            ans = answer_general(q)
        st.markdown(ans)
        st.session_state.messages.append({"role":"assistant","content":ans})

# Tools
cB, cC = st.columns([1,1])

if st.sidebar.button("‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó"):
        st.session_state.messages = []
        st.rerun()

# Example
with cB:
    if st.button("‡∏î‡∏π‡∏ß‡∏¥‡∏ä‡∏≤ '‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö' ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á)"):
        if "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤" in df_filtered.columns:
            sub = df_filtered[df_filtered["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤"].astype(str).str.contains("‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö", na=False)]
            st.dataframe(sub.reset_index(drop=True))
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏¥‡∏ä‡∏≤'")
with cC:
    st.download_button(
        "‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô CSV",
        data=df_filtered.to_csv(index=False).encode("utf-8-sig"),
        file_name="filtered_courses.csv",
        mime="text/csv"
    )
# ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏•‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏î‡∏•‡πà‡∏≤‡∏á Example
st.markdown(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á:** {len(df_filtered)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
with st.expander("‡∏î‡∏π‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á"):
    st.dataframe(df_filtered.reset_index(drop=True))